---
layout: post
title: UNIT - Unsupervised Image-to-Image Translation Networks
tags: [Image-to-image translation, GAN, VAE, Generative model, Unsupervised learning]
comments: true
---

 Liu, Ming-Yu, Thomas Breuel, and Jan Kautz. "**Unsupervised image-to-image translation networks**." *Advances in neural information processing systems*. 2017. 

Paper

- [arXiv:1703.00848](https://arxiv.org/abs/1703.00848)

Code

- [Author's repo](https://github.com/mingyuliutw/UNIT)
- [PyTorch-GAN](https://github.com/eriklindernoren/PyTorch-GAN)

Related posts

- [Two Minute Papers](https://www.youtube.com/watch?v=dqxqbvyOnMY&feature=youtu.be)
- [UNIT 介紹 - Unsupervised Image-to-Image Translation](https://xiaosean.github.io/deep learning/computer vision/2018-05-25-GAN-UNIT/) 
- [https://blog.csdn.net/leviopku/article/details/83653527](https://blog.csdn.net/leviopku/article/details/83653527)

------



## Introduction

CV problems such as super-resolution and colorization can be viewed as **image-to-image translation** problems, mapping an image in one domain to a corresponding image in another domain. 

This problem can be studied in supervised and unsupervised learning settings. Getting data used for supervised learning is burdensome, while collecting data for unsupervised learning is easier. 

In the unsupervised setting, the **coupling theory**[^1] shows that inferring the joint distribution from the two marginal distributions is a highly ill-posed problem. <u>To address this problem, the author makes a **shared-latent space** assumption, which assumes a pair of corresponding images in a different domains can be mapped to a same latent representation in a shared-latent space.</u> Then it comes to the model. 

> We model each image domain using a VAE-GAN. The training objective interacts with a weight-sharing constraint, which enforces a shared-latent space, to generate corresponding images in two domains, while the variational autoencoders relate translated images with input images in the respective domains.

The proposed framework yielded high quality image translation results and achieved SOTA accuracies on domain adaptation problems. 

The shared-latent space assumption was used in Coupled GAN[^2] for joint distribution learning. (Here's my [notes]() of Coupled GAN)

They also show that the shared-latent space constraint implies the **cycle-consistency**[^3][^4] constraint. 





[^1]: Lindvall, Torgny. *Lectures on the coupling method*. Courier Corporation, 2002.
[^2]: [Liu, Ming-Yu, and Oncel Tuzel. "Coupled generative adversarial networks." *Advances in neural information processing systems*. 2016.](https://papers.nips.cc/paper/6544-coupled-generative-adversarial-networks.pdf)
[^3]: [Zhu, Jun-Yan, et al. "Unpaired image-to-image translation using cycle-consistent adversarial networks." *Proceedings of the IEEE international conference on computer vision*. 2017.](http://openaccess.thecvf.com/content_ICCV_2017/papers/Zhu_Unpaired_Image-To-Image_Translation_ICCV_2017_paper.pdf)
[^4]: [Kim, Taeksoo, et al. "Learning to discover cross-domain relations with generative adversarial networks." *Proceedings of the 34th International Conference on Machine Learning-Volume 70*. JMLR. org, 2017.](https://arxiv.org/pdf/1703.05192.pdf)